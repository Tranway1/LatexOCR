{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "LaTeX-OCR training.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train a LaTeX OCR model\n",
    "In this brief notebook I show how you can finetune/train an OCR model.\n",
    "\n",
    "I've opted to mix in handwritten data into the regular pdf LaTeX images. For that I started out with the released pretrained model and continued training on the slightly larger corpus."
   ],
   "metadata": {
    "id": "YtR1GhYwnLnu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r396ah-Q3EQc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install pix2tex[train] -qq"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: pix2tex[train]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dZ4PLwkb3RIs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "!mkdir -p LaTeX-OCR\n",
    "os.chdir('LaTeX-OCR')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cUsTlxXV3Mot",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install gpustat -q\n",
    "!pip install opencv-python-headless==4.1.2.30 -U -q\n",
    "!pip install --upgrade --no-cache-dir gdown -q"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/chunwei/research/LaTeX-OCR/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from versions: 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68)\u001B[0m\r\n",
      "\u001B[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001B[0m\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/chunwei/research/LaTeX-OCR/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/chunwei/research/LaTeX-OCR/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# check what GPU we have\n",
    "!gpustat"
   ],
   "metadata": {
    "id": "uhLzh5vyaCaL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on querying NVIDIA devices. Use --debug flag for details\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aAz37dDU21zu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!mkdir -p dataset/data\n",
    "!mkdir images\n",
    "# Google Drive ids\n",
    "# handwritten: 13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM\n",
    "# pdf - images: 176PKaCUDWmTJdQwc-OfkO0y8t4gLsIvQ\n",
    "# pdf - math: 1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D\n",
    "!gdown -O dataset/data/crohme.zip --id 13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM\n",
    "!gdown -O dataset/data/pdf.zip --id 176PKaCUDWmTJdQwc-OfkO0y8t4gLsIvQ\n",
    "!gdown -O dataset/data/pdfmath.txt --id 1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D\n",
    "os.chdir('dataset/data')\n",
    "!unzip -q crohme.zip \n",
    "!unzip -q pdf.zip \n",
    "# split handwritten data into val set and train set\n",
    "os.chdir('images')\n",
    "!mkdir ../valimages\n",
    "!ls | shuf -n 1000 | xargs -i mv {} ../valimages\n",
    "os.chdir('../../..')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chunwei/research/LaTeX-OCR/venv/lib/python3.9/site-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM\r\n",
      "To: /Users/chunwei/research/LaTeX-OCR/notebooks/LaTeX-OCR/dataset/data/crohme.zip\r\n",
      "100%|██████████████████████████████████████| 59.8M/59.8M [00:51<00:00, 1.15MB/s]\r\n",
      "/Users/chunwei/research/LaTeX-OCR/venv/lib/python3.9/site-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=176PKaCUDWmTJdQwc-OfkO0y8t4gLsIvQ\r\n",
      "To: /Users/chunwei/research/LaTeX-OCR/notebooks/LaTeX-OCR/dataset/data/pdf.zip\r\n",
      "100%|█████████████████████████████████████████| 284M/284M [05:55<00:00, 798kB/s]\r\n",
      "/Users/chunwei/research/LaTeX-OCR/venv/lib/python3.9/site-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D\r\n",
      "To: /Users/chunwei/research/LaTeX-OCR/notebooks/LaTeX-OCR/dataset/data/pdfmath.txt\r\n",
      "100%|███████████████████████████████████████| 36.6M/36.6M [00:43<00:00, 838kB/s]\r\n",
      "xargs: illegal option -- i\r\n",
      "usage: xargs [-0opt] [-E eofstr] [-I replstr [-R replacements] [-S replsize]]\r\n",
      "             [-J replstr] [-L number] [-n number [-x]] [-P maxprocs]\r\n",
      "             [-s size] [utility [argument ...]]\r\n",
      "shuf: write error: Broken pipe\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we generate the datasets. We can string multiple datasets together to get one large lookup table. The only thing saved in these pkl files are image sizes, image location and the ground truth latex code. That way we can serve batches of images with the same dimensionality."
   ],
   "metadata": {
    "id": "2BMuIqRIqG-8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m pix2tex.dataset.dataset -i dataset/data/images dataset/data/train -e dataset/data/CROHME_math.txt dataset/data/pdfmath.txt -o dataset/data/train.pkl"
   ],
   "metadata": {
    "id": "1JebcEarl-g6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate dataset\r\n",
      "100%|███████████████████████████████████| 10822/10822 [00:01<00:00, 9773.73it/s]\r\n",
      "100%|█████████████████████████████████| 158480/158480 [00:20<00:00, 7820.35it/s]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m pix2tex.dataset.dataset -i dataset/data/valimages dataset/data/val -e dataset/data/CROHME_math.txt dataset/data/pdfmath.txt -o dataset/data/val.pkl"
   ],
   "metadata": {
    "id": "x_Orutb37xHD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate dataset\r\n",
      "0it [00:00, ?it/s]\r\n",
      "100%|█████████████████████████████████████| 6765/6765 [00:00<00:00, 8385.83it/s]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# download the weights we want to fine tune\n",
    "!curl -L -o weights.pth https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/weights.pth"
   ],
   "metadata": {
    "id": "I3iOyEEBbw58",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      "100 97.3M  100 97.3M    0     0   793k      0  0:02:05  0:02:05 --:--:--  899k2:02  0:00:08  0:01:54  734k 0   723k      0  0:02:17  0:01:21  0:00:56  356k01:52  0:00:15  899k\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# If using wandb\n",
    "!pip install -q wandb \n",
    "# you can cancel this if you don't wan't to use it or don't have a W&B acc.\n",
    "#!wandb login"
   ],
   "metadata": {
    "id": "vow2NnpHmWt0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/chunwei/research/LaTeX-OCR/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# generate colab specific config (set 'debug' to true if wandb is not used)\n",
    "!echo {backbone_layers: [2, 3, 7], betas: [0.9, 0.999], batchsize: 10, bos_token: 1, channels: 1, data: dataset/data/train.pkl, debug: true, decoder_args: {'attn_on_attn': true, 'cross_attend': true, 'ff_glu': true, 'rel_pos_bias': false, 'use_scalenorm': false}, dim: 256, encoder_depth: 4, eos_token: 2, epochs: 50, gamma: 0.9995, heads: 8, id: null, load_chkpt: 'weights.pth', lr: 0.001, lr_step: 30, max_height: 192, max_seq_len: 512, max_width: 672, min_height: 32, min_width: 32, model_path: checkpoints, name: mixed, num_layers: 4, num_tokens: 8000, optimizer: Adam, output_path: outputs, pad: false, pad_token: 0, patch_size: 16, sample_freq: 2000, save_freq: 1, scheduler: StepLR, seed: 42, temperature: 0.2, test_samples: 5, testbatchsize: 20, tokenizer: dataset/tokenizer.json, valbatches: 100, valdata: dataset/data/val.pkl} > colab.yaml"
   ],
   "metadata": {
    "id": "OnsNCLp84QSY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: parse error near `}'\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c8NU5j2k3z36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!python -m pix2tex.train --config colab.yaml"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/chunwei/research/LaTeX-OCR/pix2tex/train.py\", line 92, in <module>\r\n",
      "    with open(parsed_args.config, 'r') as f:\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'colab.yaml'\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "g3DU9KxubWgq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}